{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from utils.video_dataset import VideoDataset\n",
    "\n",
    "from models.resnet26_3D import resnet26, resnet26b\n",
    "from utils.augmentation import AugmentationGAN\n",
    "from utils.pytorch_tools import gpu_usage\n",
    "from utils.train_functions import train_one_epoch, eval_one_epoch\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import logging\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU in case it's available \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "slice_length = 10\n",
    "stride = 5\n",
    "width, height = input_shape = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoDataset(root_dir='data/data_videos_PART2',\n",
    "                       width=width, height=height,\n",
    "                       slice_length=10, stride=5)\n",
    "\n",
    "ratios = [0.98,0.01,0.01]\n",
    "\n",
    "total = len(dataset)\n",
    "lengths = [int(r * total) for r in ratios]\n",
    "lengths[-1] = total - sum(lengths[:-1])\n",
    "\n",
    "print('Total data:', total, 'and the splits are:', lengths, 'train, val, test')\n",
    "\n",
    "train, val, test = random_split(dataset, lengths=lengths)\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size, collate_fn=dataset.collate, num_workers=1, pin_memory=True)\n",
    "val_loader = DataLoader(val, batch_size=batch_size, collate_fn=dataset.collate, num_workers=1, pin_memory=True)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, collate_fn=dataset.collate, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Get train data\n",
    "# trainset = VideoDataset('data/data_videos_PART2_separated/train', height = 224, width = 224)\n",
    "# train_loader = DataLoader(trainset, batch_size = batch_size, shuffle = False, pin_memory = True)\n",
    "\n",
    "# # Get validation data\n",
    "# validationset = VideoDataset('data/data_videos_PART2_separated/validation', height = 224, width = 224)\n",
    "# validation_loader = DataLoader(validationset, batch_size = batch_size, shuffle = False, pin_memory = True)\n",
    "\n",
    "# # Get test data\n",
    "# testset = VideoDataset('data/data_videos_PART2_separated/test', height = 224, width = 224)\n",
    "# test_loader = DataLoader(testset, batch_size = batch_size, shuffle = False, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "sample_size = 1\n",
    "sample_duration = 1\n",
    "\n",
    "model = resnet26b(sample_size=sample_size,\n",
    "                sample_duration=sample_duration,\n",
    "                input_shape=input_shape,\n",
    "                num_classes=num_classes,\n",
    "                last_fc=True)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model \n",
    "num_epochs = 10 \n",
    "learning_rate = 0.0001\n",
    "\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "Path('checkpoint').mkdir(exist_ok=True)\n",
    "\n",
    "val_acc = 0\n",
    "for epoch in range(1, num_epochs+1):  # Loop over the dataset multiple times\n",
    "\n",
    "    train_results = train_one_epoch(model, train_loader, optimizer, criterion, epoch, device)\n",
    "    val_results   = eval_one_epoch(model, val_loader, criterion, epoch, device)\n",
    "\n",
    "    results = { **train_results, **val_results} # combine train and val results\n",
    "\n",
    "    if results.get('val_acc') > val_acc: # save checkpoint if val_acc is better\n",
    "        torch.save({'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    **results}, f'checkpoint/checkpoint_{epoch}.pt')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading last checkpoint\n",
    "\n",
    "last_checkpoint = sorted([f'checkpoint/checkpoint_{epoch}.pt' for epoch in range(10)], reverse=True)[0]\n",
    "checkpoint = torch.load(last_checkpoint)\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model on the testset \n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    # We are going to evaluate the model on the testset only ! \n",
    "    for data in testloader :\n",
    "        # Load inputs and labels\n",
    "        video, labels = data\n",
    "        video, labels = video.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(video)\n",
    "        # Get the indexes of maximum values along the second axis\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.size(0)\n",
    "        # Add the number of correct predictions for the batch to the total count\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test acccuracy: {(100 * correct / total)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model once it's trained"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}